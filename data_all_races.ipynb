{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastf1\n",
    "import fastf1.plotting\n",
    "import matplotlib as mpl\n",
    "from fastf1 import utils\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove warnings \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the cache\n",
    "# Direction of the cache on the computer\n",
    "fastf1.Cache.enable_cache('cache') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Check wich date to start \n",
    "year_start= 2018\n",
    "year_finish= 2018"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastF1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info_fastF1 (data_driver, session, laps , year, round):\n",
    "    \"\"\"Adds the information to the dataframe from FastF1\n",
    "\n",
    "    Args:\n",
    "        session (Sesion): session where to extract the data\n",
    "        laps (Laps): laps from the specific race to extract the data \n",
    "        data_driver (DataFrame): DataFrame where add the data\n",
    "        year(int): year of the race\n",
    "        round(int): race number (1 is the first race of the season, 2 the second...)\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: with the new data added \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all drivers\n",
    "    drivers = pd.unique(laps['Driver']) \n",
    "\n",
    "    #drivers = ['ALO'] #! TODO for all the drivers\n",
    "    for driver in drivers:\n",
    "\n",
    "        #Get the laps for the specific driver\n",
    "        driver_laps = laps.pick_driver(driver)\n",
    "\n",
    "        rows_to_concat = []\n",
    "        for lap in driver_laps.iterlaps():\n",
    "\n",
    "            #Data that is the same for all the laps\n",
    "            year = year  \n",
    "            round = round \n",
    "            race_name = session.event.EventName\n",
    "            driver_number = lap[1].DriverNumber\n",
    "            driver_name = lap[1].Driver\n",
    "            team = lap[1].Team\n",
    "            grid_position = int(session.get_driver(driver).GridPosition)\n",
    "\n",
    "            #Data that changes every lap\n",
    "            lap_number = int(lap[1].LapNumber)\n",
    "            compound = lap[1].Compound\n",
    "            tyre_life = lap[1].TyreLife\n",
    "            track_status = lap[1].TrackStatus\n",
    "            #If it has change the tire tipes, O if not 1 if yes \n",
    "            if (not pd.DataFrame(rows_to_concat).empty and pd.DataFrame(rows_to_concat)['Compound'].nunique() >1 ):\n",
    "                tyres_change= 1\n",
    "            else: \n",
    "                tyres_change= 0\n",
    "\n",
    "            #Creation of the new row\n",
    "            new_row = {'Year': year, 'RaceNumber': round, 'RaceName': race_name, 'DriverNumber': driver_number,\n",
    "                    'Driver': driver_name, 'Team': team, 'GridPosition': grid_position,\n",
    "                    'LapNumber': lap_number, 'Compound': compound,\n",
    "                    'TyreLife': tyre_life, 'TyresChange': tyres_change,\n",
    "                    'TrackStatus': track_status}\n",
    "            \n",
    "            rows_to_concat.append(new_row)\n",
    "\n",
    "        #is concat beacuse append with be deprecated in a future version  \n",
    "        data_driver = pd.concat([data_driver, pd.DataFrame(rows_to_concat)], ignore_index=True)\n",
    "    \n",
    "    return data_driver\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver codes  \n",
    "* This is necesary to be able to iteract between the two sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary because in the lap table we have the user id, and in fastF1 what we have is the code \n",
    "dict_code_drivers ={}\n",
    "\n",
    "for year in list(range(year_start,year_finish+1)):\n",
    "    url = 'http://ergast.com/api/f1/{}/drivers.json?limit=10000'\n",
    "    r = requests.get(url.format(year))\n",
    "    json = r.json()\n",
    "\n",
    "    for item in json['MRData']['DriverTable']['Drivers']:\n",
    "        if (item['driverId'] not in dict_code_drivers):\n",
    "            dict_code_drivers[item['driverId']] = item['code']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function update \n",
    "#### Calculate the position, time lap and time in the race of each driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_position = pd.DataFrame()\n",
    "\n",
    "def add_info_Ergast (laps_position, numberLaps, year, round):\n",
    "    \"\"\"Create and add the information form Ergast\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        laps_position (DataFrame): DataFrame where add the data\n",
    "        numberLaps (int): number of laps of this race\n",
    "        year(int): year of the race\n",
    "        round(int): race number\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: with the data added \n",
    "    \"\"\"\n",
    "\n",
    "    #-----AUXILIARY INFORMATION NEDED-----\n",
    "\n",
    "    #Qualy results \n",
    "    results_qualy = {}\n",
    "    url = 'http://ergast.com/api/f1/{}/{}/qualifying.json?limit=100000'\n",
    "    r = requests.get(url.format(year,round))\n",
    "    json = r.json()\n",
    "    for item in json['MRData']['RaceTable']['Races'][0]['QualifyingResults']:\n",
    "        results_qualy[item['Driver']['code']] = item['position']\n",
    "        \n",
    "    #Driver standing and points before starting the race\n",
    "    #? TODO is this useful ? and the tams championship\n",
    "    drivers_standings = {}\n",
    "    #points_championship = {}\n",
    "    #In the fist race there is no results \n",
    "    if (round-1 >0): \n",
    "        url = 'http://ergast.com/api/f1/{}/{}/driverStandings.json?limit=10000'\n",
    "        r = requests.get(url.format(year,round-1))\n",
    "        json = r.json()\n",
    "        for item in json['MRData']['StandingsTable']['StandingsLists'][0]['DriverStandings']: \n",
    "            drivers_standings[item['Driver']['code']] = item['position']\n",
    "            #points_championship[item['Driver']['code']] = item['points']\n",
    "\n",
    "    #Race Status (if finish or has a problem)\n",
    "    results_status = {}\n",
    "    url = 'http://ergast.com/api/f1/{}/{}/results.json?limit=10000'\n",
    "    r = requests.get(url.format(year,round))\n",
    "    json = r.json()\n",
    "    for item in json['MRData']['RaceTable']['Races'][0]['Results']: \n",
    "        results_status[item['Driver']['code']] = item['status']\n",
    "\n",
    "    #-----ADD VALUES-----\n",
    "\n",
    "    # dictionary to store total lap times for each driver\n",
    "    driver_lap_times = {}\n",
    "\n",
    "    #Get information from each lap\n",
    "    for lapN in range(1, numberLaps+1):\n",
    "        url = 'http://ergast.com/api/f1/{}/{}/laps/{}.json?limit=10000'\n",
    "        r = requests.get(url.format(year, round, lapN)) \n",
    "        json = r.json()\n",
    "        #Iterate over le response\n",
    "        if  len(json['MRData']['RaceTable']['Races'])>0 and len(json['MRData']['RaceTable']['Races'][0]['Laps'])>0 and len(json['MRData']['RaceTable']['Races'][0]['Laps'][0]['Timings'])>0:\n",
    "            for item in json['MRData']['RaceTable']['Races'][0]['Laps'][0]['Timings']:\n",
    "                driver = dict_code_drivers.get(item['driverId'])\n",
    "                qualyPosition = results_qualy.get(driver)\n",
    "                position = item['position']\n",
    "                lap_time = datetime.strptime(item['time'], '%M:%S.%f').time()\n",
    "                resultStatus = results_status.get(driver)\n",
    "\n",
    "                #Standings and points\n",
    "                if len(drivers_standings) == 0 : #In the fist race there is no results \n",
    "                    driverStandings= 0\n",
    "                    #pointsChampionship= 0\n",
    "                else:\n",
    "                    driverStandings= drivers_standings.get(driver)\n",
    "                    #pointsChampionship = points_championship.get(driver)\n",
    "\n",
    "                # get total lap time for the current driver\n",
    "                if driver in driver_lap_times:\n",
    "                    total_time = driver_lap_times[driver] + timedelta(minutes=lap_time.minute, seconds=lap_time.second, microseconds=lap_time.microsecond)\n",
    "                else:\n",
    "                    total_time = timedelta(minutes=lap_time.minute, seconds=lap_time.second, microseconds=lap_time.microsecond)\n",
    "\n",
    "                # update the dictionary with the total lap time for the current driver\n",
    "                driver_lap_times[driver] = total_time\n",
    "                \n",
    "                # append the lap data to the dataframe\n",
    "                laps_position = laps_position.append({'LapNumber': lapN, 'Driver': driver, 'ResultStatus':resultStatus, \n",
    "                                        'QualyPosition': qualyPosition, 'DriverStandings' :driverStandings, \n",
    "                                        'Position': position, 'TimeLap': lap_time, 'RaceTimeProgress': total_time \n",
    "                                        }, ignore_index=True)\n",
    "\n",
    "    return laps_position"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the distance between the driver ahead and behind,and the distance to the leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_add_distances (laps_position):\n",
    "    \"\"\"Add for each driver:\n",
    "            the time distance to the driver ahead\n",
    "            the time distance to the driver behind\n",
    "            the time distance to the leader (also call gap)\n",
    "            \n",
    "    This new colums are calculated with the previus information that we already have in the dataframe\n",
    "    That is the reason that is done later, we need the complete information\n",
    "            \n",
    "    Args:\n",
    "        laps_position (DataFrame): where add the data\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: with the data added\n",
    "    \"\"\"\n",
    "\n",
    "    #Diference with the car ahead \n",
    "    laps_position['NextTime'] = laps_position.groupby('LapNumber')['RaceTimeProgress'].shift(1)\n",
    "    laps_position['TimeDiffAhead'] = laps_position['RaceTimeProgress']  - laps_position['NextTime']  \n",
    "    laps_position['TimeDiffAhead'] = laps_position['TimeDiffAhead'].fillna(value=pd.Timedelta(0)) #The first driver does't have diference with others\n",
    "    laps_position = laps_position.drop(columns=['NextTime'])\n",
    "\n",
    "    #Diference with the car behind \n",
    "    laps_position['NextTime'] = laps_position.groupby('LapNumber')['RaceTimeProgress'].shift(-1)\n",
    "    laps_position['TimeDiffBehind'] =  laps_position['NextTime']  - laps_position['RaceTimeProgress']  \n",
    "    laps_position['TimeDiffBehind'] = laps_position['TimeDiffBehind'].fillna(value=pd.Timedelta(0)) #The last driver does't have diference with others\n",
    "    laps_position = laps_position.drop(columns=['NextTime'])\n",
    "\n",
    "    #Diference with the leader\n",
    "    grouped = laps_position.groupby('LapNumber')\n",
    "    leader_progress = grouped['RaceTimeProgress'].transform(lambda x: x[x.idxmin()]) # calculate leader's race time progress in each group\n",
    "    laps_position['TimeDiffToLeader'] = laps_position['RaceTimeProgress'] - leader_progress     # calculate difference to leader for each driver in each group\n",
    "    laps_position = laps_position.drop(columns=['RaceTimeProgress'])\n",
    "\n",
    "\n",
    "    return laps_position"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pit stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pit_stops_data (laps_position, year, round):\n",
    "    \"\"\"Added the following new colums, related with the pit stops, for each lap:\n",
    "            * HasPitLap: if ther is a pit stop in the lap (0: no, 1:yes)\n",
    "            * TimePit: time of the pit stop, in case that there is pit (0 if not)\n",
    "            * NumberPitStops: number of pit stops that the driver has done till this point\n",
    "\n",
    "            * DriverAhead: what is the driver ahead (the first doesn't have any)\n",
    "            * DriverBehind: what is the driver behind (the last doesn't have any)\n",
    "\n",
    "            * DriverAheadPit: if the driver that is ahead has pit in this stint \n",
    "            * DriverBehindPit: if the driver that is behind has pit in this stint \n",
    "                - 0: no, 1:yes for both \n",
    "                - a stint refers to the period of time during a race when a driver stays out on the track without pitting \n",
    "    Args:\n",
    "        laps_position (DataFrame): DataFrame where add the data\n",
    "        year(int): year of the race\n",
    "        round(int): race number\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: with the data added \n",
    "    \"\"\"\n",
    "\n",
    "    #--------CREATION AUXILIAR DATAFRAME -------\n",
    "    #Creation of the dataframe with the information of the pit stops for the race\n",
    "    pitStops = pd.DataFrame()\n",
    "    url = 'http://ergast.com/api/f1/{}/{}/pitstops.json?limit=10000'\n",
    "    r = requests.get(url.format(year,round))\n",
    "    json = r.json()\n",
    "\n",
    "    if (len(json['MRData']['RaceTable']['Races'])==0 or len(json['MRData']['RaceTable']['Races'][0]['PitStops'])==0):\n",
    "        return laps_position #There is no information\n",
    "\n",
    "    for item in json['MRData']['RaceTable']['Races'][0]['PitStops']: \n",
    "        #Get info\n",
    "        driver = dict_code_drivers.get(item['driverId'])\n",
    "        lap = item['lap']\n",
    "        stopNumber = item['stop']\n",
    "        duration = item['duration'] \n",
    "        #Add to the dataframe\n",
    "        pitStops = pitStops.append({'driver': driver, 'lap': lap, 'stopNumber': stopNumber, 'duration': duration}, ignore_index=True)\n",
    "\n",
    "    #---------- ADD TO THE DATAFRAME--------\n",
    "    #Creation of new colums that will be added in the dataframe\n",
    "    #Numeric\n",
    "    laps_position[\"TimePit\"] = 0\n",
    "    laps_position[\"NumberPitStops\"] = 0\n",
    "    #binari 0 no 1 yes (If the car has stop is this stint)\n",
    "    laps_position[\"HasPitLap\"] = 0\n",
    "\n",
    "    #------------- LAP, LAP TIME, NUMBER OF PITS --------\n",
    "    #Itereate over the dataframe to add Pit, time,number of pits\n",
    "    for index, row in laps_position.iterrows():   \n",
    "\n",
    "        #information of the pit for the driver in the specific lap \n",
    "        value_pit = pitStops[(pitStops['driver'] == row['Driver']) & (pitStops['lap'] == str(row['LapNumber']))]\n",
    "\n",
    "        if not value_pit.empty: #There is a pit stop \n",
    "            laps_position.loc[index, 'HasPitLap'] = 1\n",
    "            laps_position.loc[index, 'TimePit'] = value_pit['duration'].item()\n",
    "            \n",
    "            #For have a count of the number of pit stops (needed for later)\n",
    "            #The number of stops on the previous lap is displayed, if there has been a pit stop this number is increased. \n",
    "            if (row['LapNumber']>1):\n",
    "                laps_position.loc[index, 'NumberPitStops'] = laps_position.loc[(laps_position['Driver'] == row['Driver']) & (laps_position['LapNumber'] == (row['LapNumber']-1)), 'NumberPitStops'].item()+1\n",
    "        elif (row['LapNumber']>1): \n",
    "            laps_position.loc[index, 'NumberPitStops'] = laps_position.loc[(laps_position['Driver'] == row['Driver']) & (laps_position['LapNumber'] == (row['LapNumber']-1)), 'NumberPitStops'].item()\n",
    "        \n",
    "    #-----------DRIVER AHEAD AND BEHIND HAS STOP --------\n",
    "    #Creation of columns with the car ahead and behind, \n",
    "    #We have nulls, whether it is the first or the last one. \n",
    "    #? TODO delete them \n",
    "    laps_position['DriverAhead'] = laps_position.groupby('LapNumber')['Driver'].shift(1)\n",
    "    laps_position['DriverBehind'] = laps_position.groupby('LapNumber')['Driver'].shift(-1)\n",
    "\n",
    "    #Calculation if the driver ahead an behind has stop\n",
    "    #binari 0 no 1 yes\n",
    "    laps_position[\"DriverAheadPit\"] = 0\n",
    "    laps_position[\"DriverBehindPit\"] = 0\n",
    "\n",
    "    #It is done in another for, because I need the values that are calculated in the previous one\n",
    "    for index, row in laps_position.iterrows():  \n",
    "        #Has the driver ahead do a pit stop \n",
    "        #If the driver ahead is Nan is because is the fist one \n",
    "        if type(row['DriverAhead']) == str: ## if is not str is when is Nan \n",
    "            n_pits_car_ahead = laps_position.loc[(laps_position['Driver'] == row['DriverAhead']) & (laps_position['LapNumber'] == (row['LapNumber']))]['NumberPitStops'].item()\n",
    "            if (n_pits_car_ahead > row['NumberPitStops']):\n",
    "                laps_position.loc[index, 'DriverAheadPit'] = 1\n",
    "\n",
    "        #Has the driver behind do a pit stop \n",
    "        #If the driver behind is Nan is because is the last one \n",
    "        if type(row['DriverBehind']) == str: ## if is not str is when is Nan \n",
    "            n_pits_car_ahead = laps_position.loc[(laps_position['Driver'] == row['DriverBehind']) & (laps_position['LapNumber'] == (row['LapNumber']))]['NumberPitStops'].item()\n",
    "            if (n_pits_car_ahead > row['NumberPitStops']):\n",
    "                laps_position.loc[index, 'DriverBehindPit'] = 1\n",
    "    \n",
    "    #return the dataframe with all the new data\n",
    "    return laps_position"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was a good pit stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_pit (laps_position, numberLaps):\n",
    "    \"\"\" Cretes and calculate a new colum in the dataframe, to check if was a good pit\n",
    "    A good pit is calculated if at the end of the stint the position is equal to or better than before the pit was made\n",
    "\n",
    "    Args:\n",
    "        laps_position (DataFrame): DataFrame where add the data\n",
    "        numberLaps (int): number of laps of this race\n",
    "\n",
    "    Returns:\n",
    "       DataFrame: with the data added \n",
    "    \"\"\"\n",
    "\n",
    "    #creation of the new colum 0 no 1 yes\n",
    "    laps_position[\"GoodPitStop\"] = 0\n",
    "\n",
    "    #iterate over the information and calculate if was a good pit \n",
    "    for index, row in laps_position.iterrows():  \n",
    "        #if in this lap there is a pit stop \n",
    "        if 'HasPitLap' in row and row[\"HasPitLap\"] ==1 :\n",
    "            posInicial = row['Position']\n",
    "            #Check if in this stint he has improved his position or stayed the same (with that you can say it is a good pit)\n",
    "            for l in range(row['LapNumber'] +1 , numberLaps+1):\n",
    "                \n",
    "                #New laps to compare to the original \n",
    "                compare = laps_position.loc[(laps_position['Driver'] == row['Driver']) & (laps_position['LapNumber'] == l)]\n",
    "                \n",
    "                if ( not compare.empty): #check that there is information for this lap, if the car ends before \n",
    "                    if (row['NumberPitStops'] != compare['NumberPitStops'].item()): #change of stint\n",
    "                        if (row['Position'] >= compare['Position'].item()): #compare if the new position is better or the same\n",
    "                            laps_position.loc[index, 'GoodPitStop'] = 1\n",
    "                        break #we have the information that we want\n",
    "\n",
    "                    if (l == numberLaps): #last lap, is also an end of stint \n",
    "                        if (row['Position'] >= compare['Position'].item()): #compare if the new position is better or the same\n",
    "                            laps_position.loc[index, 'GoodPitStop'] = 1\n",
    "\n",
    "    return laps_position"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the dataframe \n",
    "df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='ergast.com', port=443): Max retries exceeded with url: /api/f1/current/last/results.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[1;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:635\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    628\u001b[0m         (\n\u001b[0;32m    629\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem time is way off (before \u001b[39m\u001b[39m{\u001b[39;00mRECENT_DATE\u001b[39m}\u001b[39;00m\u001b[39m). This will probably \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m         SystemTimeWarning,\n\u001b[0;32m    633\u001b[0m     )\n\u001b[1;32m--> 635\u001b[0m sock_and_verified \u001b[39m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[0;32m    636\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    637\u001b[0m     cert_reqs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_reqs,\n\u001b[0;32m    638\u001b[0m     ssl_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_version,\n\u001b[0;32m    639\u001b[0m     ssl_minimum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_minimum_version,\n\u001b[0;32m    640\u001b[0m     ssl_maximum_version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_maximum_version,\n\u001b[0;32m    641\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    642\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    643\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    644\u001b[0m     cert_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    645\u001b[0m     key_file\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    646\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    647\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    648\u001b[0m     ssl_context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssl_context,\n\u001b[0;32m    649\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    650\u001b[0m     assert_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_hostname,\n\u001b[0;32m    651\u001b[0m     assert_fingerprint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_fingerprint,\n\u001b[0;32m    652\u001b[0m )\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock_and_verified\u001b[39m.\u001b[39msocket\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:774\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    772\u001b[0m         server_hostname \u001b[39m=\u001b[39m normalized\n\u001b[1;32m--> 774\u001b[0m ssl_sock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    775\u001b[0m     sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    776\u001b[0m     keyfile\u001b[39m=\u001b[39;49mkey_file,\n\u001b[0;32m    777\u001b[0m     certfile\u001b[39m=\u001b[39;49mcert_file,\n\u001b[0;32m    778\u001b[0m     key_password\u001b[39m=\u001b[39;49mkey_password,\n\u001b[0;32m    779\u001b[0m     ca_certs\u001b[39m=\u001b[39;49mca_certs,\n\u001b[0;32m    780\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49mca_cert_dir,\n\u001b[0;32m    781\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49mca_cert_data,\n\u001b[0;32m    782\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    783\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    784\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    785\u001b[0m )\n\u001b[0;32m    787\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\ssl_.py:459\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\ssl_.py:503\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    524\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1075\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1076\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1347\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[1;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[0;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[1;31mSSLError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[1;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    846\u001b[0m )\n\u001b[0;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='ergast.com', port=443): Max retries exceeded with url: /api/f1/current/last/results.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m#Since the season 2023 is still going ()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#The numberCircuitsSeason will be 23, but we don't have info of the race\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m#So we stop the for in the last race that we have info \u001b[39;00m\n\u001b[0;32m     20\u001b[0m url_last \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://ergast.com/api/f1/current/last/results.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 21\u001b[0m r_last \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url_last\u001b[39m.\u001b[39;49mformat(year))\n\u001b[0;32m     22\u001b[0m json_last \u001b[39m=\u001b[39m r_last\u001b[39m.\u001b[39mjson()\n\u001b[0;32m     23\u001b[0m round_last\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m (json_last[\u001b[39m'\u001b[39m\u001b[39mMRData\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mRaceTable\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mround\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\adapters.py:517\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='ergast.com', port=443): Max retries exceeded with url: /api/f1/current/last/results.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))"
     ]
    }
   ],
   "source": [
    "#NOTE The frist time (if is not in chache)\n",
    "# Since there is a lot of data that needs to be download this process takes some time \n",
    "# For each race takes like 1 min to load the data\n",
    "# And then a bit more than 1 min to all the calculations \n",
    "\n",
    "#For each year \n",
    "for year in list(range(year_start,year_finish+1)):\n",
    "    \n",
    "    df_year= pd.DataFrame()\n",
    "\n",
    "    #Get number of circuits in that year \n",
    "    url = 'http://ergast.com/api/f1/{}/circuits.json?limit=10000'\n",
    "    r = requests.get(url.format(year,round))\n",
    "    json = r.json()\n",
    "    numberCircuitsSeason = int(json['MRData']['total'])\n",
    "\n",
    "    #Since the season 2023 is still going ()\n",
    "    #The numberCircuitsSeason will be 23, but we don't have info of the race\n",
    "    #So we stop the for in the last race that we have info \n",
    "    url_last = 'https://ergast.com/api/f1/current/last/results.json'\n",
    "    r_last = requests.get(url_last.format(year))\n",
    "    json_last = r_last.json()\n",
    "    round_last= int (json_last['MRData']['RaceTable']['round'])\n",
    "    year_last = int (json_last['MRData']['RaceTable']['season'])\n",
    "    #For each race in the year \n",
    "    for round in range(1, numberCircuitsSeason+1) : \n",
    "        #If that race of the season has not occur yet we stop \n",
    "        if year == year_last and round > round_last:\n",
    "            break\n",
    "        #Creation of the Dataframes to add the data \n",
    "        df_FastF1 = pd.DataFrame()\n",
    "        df_Ergast = pd.DataFrame()\n",
    "\n",
    "        #creation the session for this race to acces FastF1\n",
    "        session = fastf1.get_session(year, round, 'R')\n",
    "        session.load()\n",
    "\n",
    "        try:\n",
    "            #Load the laps of this session \n",
    "            laps = session.load_laps(with_telemetry=True)\n",
    "            \n",
    "            #Add data from FastF1\n",
    "            df_FastF1 = add_info_fastF1 (df_FastF1, session, laps, year, round)\n",
    "\n",
    "            #Get number of laps (neded for Ergast)\n",
    "            numberLaps  = int(max(df_FastF1['LapNumber']))\n",
    "\n",
    "            #Add data from Ergast\n",
    "            df_Ergast =  add_info_Ergast (df_Ergast, numberLaps, year, round)\n",
    "\n",
    "            #Calculate and add distances to driver ahead, behind and leader \n",
    "            df_Ergast = calculate_add_distances (df_Ergast)\n",
    "\n",
    "            #Calculate and add the information related to pit stops \n",
    "            df_Ergast = pit_stops_data (df_Ergast, year, round)\n",
    "\n",
    "            #Calculate if the pit was a good pit \n",
    "            df_Ergast = good_pit (df_Ergast, numberLaps)\n",
    "\n",
    "            #Combine both dataframes , the commun colums are LapNumber and Driver\n",
    "            data_merge = pd.merge(df_FastF1, df_Ergast, on=['LapNumber', 'Driver'])\n",
    "\n",
    "            #Add the data of this race to de year DataFrame \n",
    "            df_year = pd.concat([df_year, data_merge], ignore_index=True)\n",
    "        except:\n",
    "            continue\n",
    "    #Export Dataframe per year\n",
    "    name_file = 'data/' + str(year) + '.csv'\n",
    "    df_year.to_csv(name_file, index=False, header=True, sep ='\\t')\n",
    "\n",
    "    #add the data to the full dataframe \n",
    "    df = pd.concat([df, df_year], ignore_index=True)\n",
    "    \n",
    "#Export dataframe \n",
    "df.to_csv('data/combined_dataframe.csv', index=False, header=True, sep ='\\t' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
