{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix_classifier_from_predictions(classifier, X, y, name = \"\"):\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X,\n",
    "        y,\n",
    "        display_labels=['0','1'],\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=None,\n",
    "    )\n",
    "    disp.ax_.set_title('Confusion Matrix: ' + name)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.read_csv(\"data/encoded_data.csv\", sep=\"\\t\")\n",
    "df = pd.read_csv(\"data/combined_dataframe_clean.csv\", sep=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years= [2019, 2020, 2021]\n",
    "test_years = [2022]\n",
    "\n",
    "y_train_years_GP = df[df['Year'].isin(train_years)]['GoodPitStop']\n",
    "y_test_years_GP= df[df['Year'].isin(test_years)]['GoodPitStop']\n",
    "X_train_years_GP = df_encoded.loc[y_train_years_GP.index]\n",
    "X_test_years_GP = df_encoded.loc[y_test_years_GP.index]\n",
    "\n",
    "y_train_years_HP = df[df['Year'].isin(train_years)]['HasPitLap']\n",
    "y_test_years_HP= df[df['Year'].isin(test_years)]['HasPitLap']\n",
    "X_train_years_HP = df_encoded.loc[y_train_years_HP.index]\n",
    "X_test_years_HP = df_encoded.loc[y_test_years_HP.index]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train_GP, X_test_GP, y_train_GP, y_test_GP = train_test_split(df_encoded, df['GoodPitStop'], test_size=0.3, random_state=4815)\n",
    "X_train_HP, X_test_HP, y_train_HP, y_test_HP = train_test_split(df_encoded, df['HasPitLap'], test_size=0.3, random_state=4815)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA object with the specified variance threshold\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# Fit the PCA on the training data and transform both the training and test data\n",
    "X_train_pca = pca.fit_transform(X_train_HP)\n",
    "X_test_pca = pca.transform(X_test_HP)\n",
    "\n",
    "# Print the number of features after PCA\n",
    "print(f\"Number of features after PCA: {X_train_pca.shape[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Creation an SVM classifier\n",
    "svm_model = svm.SVC(class_weight=\"balanced\")\n",
    "\n",
    "#Definition the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform cross-validation and grid search\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train_HP, y_train_HP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best hyperparameters and evaluate on the validation set\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_test_pred = best_svm.predict(X_test_HP)\n",
    "f1_test = f1_score(y_test_HP, y_test_pred)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Test F1 score:\", f1_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
